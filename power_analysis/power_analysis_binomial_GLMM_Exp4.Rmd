---
title: "Exp4 - power analysis - binomial GLMM"
author: "Christoph VÃ¶lter"
date: "31/05/2020"
output: 
  html_document:
    theme: united
    toc: yes
    toc_depth: 4
    toc_float: yes
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE)
library(tidyverse)
library(cowplot)
library("gghalves")

load("power_sim_disjsyll_1000iter_Exp4.RData")
```

## Generate data

```{r echo=FALSE, include=FALSE}

set.seed(1)
n.subject <- 16 # number subjects
n.per.subject <- 12 # observations per subject
n.per.condition <- 12 # observations per subject and condition
subj.id <- as.factor(paste("subj", 1:n.subject, sep = "."))
age_range <- c(12:31) # age range between 8 and 40
control.per <- 1 / 4 # performance in control condition
test.per <- c(0.55, 0.65) # performance in test condition

start.data <- data.frame(subj.id)
# duplicate rows according to the number obs. per subject:
start.data <- start.data[rep(x = 1:nrow(start.data), times = n.per.subject), ]
start.data <- as.data.frame(start.data)
names(start.data) <- "subj.id"

# add condition and trial number
start.data <- data.frame(expand.grid(subj.id = subj.id, condition = c("control", "test"), trial = c(1:n.per.condition)))

# add order
start.data$order <- as.factor(rep(x = c("test_first", "control_first"), times = n.subject / 2))[as.numeric(start.data$subj.id)]

start.data$order2 <- ifelse((start.data$order == "test_first" & start.data$condition == "test") |
  (start.data$order == "control_first" & start.data$condition == "control"), 1, 2)


# add demographics  (if it should be generated in each loop)
chimp.demo <- read.csv("data/chimp_demographics.csv")
start.data$subject_name <- as.factor(rep(x = chimp.demo$Subject, times = n.per.subject))[as.numeric(start.data$subj.id)]
start.data$age <- as.numeric(rep(x = chimp.demo$Age, times = n.per.subject))[as.numeric(start.data$subj.id)]
start.data$sex <- as.factor(rep(x = chimp.demo$Sex, times = n.per.subject))[as.numeric(start.data$subj.id)]


# z-transformation of covariates
start.data$z.age <- as.vector(scale(start.data$age))
start.data$z.trial <- as.vector(scale(start.data$trial))
start.data$z.order <- as.vector(scale(as.numeric(start.data$order2)))

# dummy code factors
start.data$condition.dummy <- as.numeric(start.data$condition == levels(start.data$condition)[2])
start.data$order.dummy <- as.numeric(start.data$order == levels(start.data$order)[2])

# center condition for random slopes:
start.data$condition.c <- as.numeric(start.data$condition) - mean(as.numeric(start.data$condition))
start.data$order.c <- as.numeric(start.data$order) - mean(as.numeric(start.data$order))

# checks:
# does each subject have only one sex and age?
xx <- table(start.data$subj.id, start.data$sex)
range(apply(X = xx > 0, MARGIN = 1, sum)) # should be 1 and 1

xx <- table(start.data$subj.id, start.data$age)
range(apply(X = xx > 0, MARGIN = 1, sum)) # should be 1 and 1

xx <- table(start.data$subj.id, start.data$condition)
range(apply(X = xx > 0, MARGIN = 1, sum))

xx <- table(start.data$subj.id, start.data$trial)
range(apply(X = xx > 0, MARGIN = 1, sum))

xx <- table(start.data$condition, start.data$order)
range(apply(X = xx > 0, MARGIN = 1, sum))

xx <- table(start.data$subj.id, start.data$order)
range(apply(X = xx > 0, MARGIN = 1, sum))
```


## Simulation

```{r eval=FALSE, include=FALSE}
n.simus <- 1000 # small number for testing
r.effects <- c(0.175, 0.35, 0.7) # random effects to be simulated
# with the intercept being -0.6931472 (qlogis(1/3)) we could make the following
# guesses for the random intercept:
#- 0.175: tiny random intercepts effect
#- 0.35: moderate random intercepts effect
#- 0.7: strong random intercepts effect
#- 1.4: very strong random intercepts effect

r.slope.con <- c(0.45, 0.9)
# with the intercept being -0.8938179 (qlogis(1/3)-qlogis(0.55)) we could make the following
# guesses for the random slopes:
#- 0.225: tiny random slopes effect
#- 0.45: moderate random slopes effect
#- 0.9: strong random slopes effect
#- 1.8: very strong random slopes effect

r.slope.trial <- 0.1
#r.slope.order <- 0.1 #if order is included as within-subject factor.

# create object to store the simulation parameters and results:
all.res <- data.frame(expand.grid(
  n.per.subject = n.per.subject, r.effect = r.effects, 
  r.slope.con = r.slope.con, r.slope.trial = r.slope.trial, #r.slope.order = r.slope.order,
  test.per = test.per,
  simu = 1:n.simus
))
all.res$icpt <- NA
all.res$conditiontest <- NA
all.res$re.sd <- NA
all.res$warns.full <- NA
all.res$warns.null <- NA
all.res$lrt.p.con <- NA
all.res$full.null.p <- NA

all.ests=matrix(NA, nrow=n.simus, ncol=1)
colnames(all.ests)=c("lrt.p.con")

# create data frame with design:
## done above

# load packages needed:
library(lme4)
# Loading required package: Matrix
library(kyotil) # we want to store info about convergence issues

# define control structure to make convergence more likely:
contr <- glmerControl(optimizer = "bobyqa", optCtrl = list(maxfun = 10000))

xdata <- start.data



m.mat <- model.matrix(object = ~condition + z.age + sex + z.trial + order, data = xdata) # create model martix

# run simulation
for (i in 1:nrow(all.res)) {
  set.seed(i) # allows to later replicate individual simulations

  # xdata <- start.data[rep(x = 1:nrow(start.data), each = all.res[i, "n.per.subject"]), ]  # replicate rows in start.data according to sample size

  # add age  (if it should be generated in each loop)
  # age <- sample(x = age_range, size = length(unique(start.data$subj.id)), replace = T)
  # start.data$age <- as.numeric(age[as.numeric(start.data$subj.id)])
  # add sex (if it should be generated in each loop)
  # sex <- sample(x = c("F", "M"), size = length(unique(start.data$subj.id)), replace = T)
  # start.data$sex <- as.factor(sex[as.numeric(start.data$subj.id)])
  
  coefs <- c(
  "(Intercept)" = log(control.per / (1 - control.per)),
  "conditiontest" = log(all.res[i, "test.per"] / (1 - all.res[i, "test.per"] )) - log(control.per / (1 - control.per)),
  "z.age" = 0,
  "sexMale" = 0,
  "z.trial" = 0,
  "ordertest_first" = 0
)
  
  LP <- m.mat[, names(coefs)] %*% coefs # LP wrt fixed effects

  # add random effect to linear predictor:
  LP <- LP + rnorm(n = n.subject, sd = all.res[i, "r.effect"])[as.numeric(xdata$subj.id)] +
    rnorm(n = n.subject, sd = all.res[i, "r.slope.con"])[as.numeric(xdata$subj.id)] * xdata$condition.dummy +
    rnorm(n = n.subject, sd = all.res[i, "r.slope.trial"])[as.numeric(xdata$subj.id)] * xdata$z.trial #+
  # rnorm(n = n.subject, sd = all.res[i, "r.slope.order"])[as.numeric(xdata$subj.id)]*xdata$z.order

  # generate response:
  xdata$correct <- rbinom(n = nrow(xdata), size = 1, prob = exp(LP) / (1 + exp(LP)))

  # fit full model:
  full <- keepWarnings(glmer(correct ~ condition + z.age + sex + z.trial + order + (1 + condition.c + z.trial || subj.id),
    data = xdata, family = binomial, control = contr
  ))
  # fit null model:
  null <- keepWarnings(glmer(correct ~ z.trial + order + (1 + condition.c + z.trial || subj.id),
    data = xdata, family = binomial, control = contr
  ))

  # store results:
  all.res[i, c("icpt", "conditiontest", "z.age", "sexMale", "z.trial", "ordertest_first")] <- fixef(full$value)
  all.res[i, "re.sd"] <- as.data.frame(summary(full$value)$varcor)[1, "sdcor"]
  all.res[i, "warns.full"] <- nchar(paste(full$warnings, collapse = ""))
  all.res[i, "warns.null"] <- nchar(paste(null$warnings, collapse = ""))
  all.res[i, "lrt.p.con"] <- as.data.frame(drop1(full$value, test = "Chisq"))["condition", "Pr(Chi)"]
  all.res[i, "full.null.p"] <- as.data.frame(anova(null$value, full$value, test = "Chisq"))[2, "Pr(>Chisq)"]
}


#save.image("power_sim_disjsyll_1000iter_Exp4.RData")
```

## Evaluation of results 

* number of warning per combinations of random effects (out of 1000 models per cell)  
Full model:  
```{r echo=FALSE}
#full model
tapply(X=all.res[, "warns.full"]>0, INDEX=all.res[, c("r.slope.con", "r.effect")],
FUN=sum)
#warning codes: 
#363: unable to evaluate scaled gradient. Model failed to converge: degenerate  Hessian with 1 negative eigenvalues
#205: Model is nearly unidentifiable: large eigenvalue ratio - Rescale variables?
```

Null model:  
```{r echo=FALSE}
#null model: 
tapply(X=all.res[, "warns.null"]>0, INDEX=all.res[, c("r.slope.con", "r.effect")],
FUN=sum)
```

* plotting the estimates (all models)

```{r echo=FALSE}
par(mar=c(3, 3, 0.2, 0.2), mgp=c(1.7, 0.3, 0), tcl=-0.15, las=1)
plot(
  x = as.numeric(as.factor(rep(
    x = c("icpt", "conditiontest", "re.sd"),
    each = nrow(all.res)
  ))),
  y = unlist(all.res[, c("icpt", "conditiontest", "re.sd")]),
  pch = 19, col = grey(level = 0.2, alpha = 0.2),
  xaxt = "n", xlim = c(0.5, 3.5), ylab = "estimate", xlab = ""
)
mtext(text = c("icpt", "conditiontest", "re.sd"), side = 1, at = 1:3, line = 0.2)
```

## Only models that converged are evaluated from here on:  

```{r include=FALSE}
all.res2=subset(all.res, warns.full==0)

```

### How many models converged and have a significant LRT of condition or a significant full-null model comparison?   
```{r echo=FALSE}
lrt.data <- all.res2 %>%
  group_by(test.per, r.effect, r.slope.con) %>%
  summarise(lrt.p.con.mean = mean(lrt.p.con), #mean condition p-value of the models that converged
            n.sign.lrt = length(lrt.p.con[lrt.p.con < 0.05]), #number of significant condition effects
            n.lrt = n.simus,#length(lrt.p.con), #number of iterations
            proportion.sign.lrt = length(lrt.p.con[lrt.p.con < 0.05]) / n.simus, #proportion of significant condition effects
            full.null.p.mean = mean(full.null.p), #mean full-null model p-value of the models that converged
            n.sign.full.null.p = length(full.null.p[full.null.p < 0.05]), #number of significant full-null model comparisons
            n.fn = n.simus, #length(full.null.p), #number of iterations 
            proportion.sign.fn = length(full.null.p[full.null.p < 0.05]) /n.simus) #proportion of significant full-null model comparisons

lrt.data
```

#### Plotting the proportion of significant Full-null model comparisons

```{r echo=FALSE}

ggplot(data = lrt.data, aes(y=proportion.sign.fn))+
  geom_point(aes(x=as.factor(r.effect), y=proportion.sign.fn))+
  geom_boxplot(aes(x=as.factor(r.effect), y=proportion.sign.fn, group=r.effect))+
  #theme_classic()+
  ylim(0.3, 1)+
  geom_hline(yintercept=0.8, colour="red", lty=2)+
  facet_wrap(~r.slope.con)

```



#### Plotting the proportion of significant LRTs for the predictor variable condition

```{r echo=FALSE}

ggplot(data = lrt.data, aes(y=proportion.sign.lrt))+
  geom_point(aes(x=as.factor(r.effect), y=proportion.sign.lrt))+
  geom_boxplot(aes(x=as.factor(r.effect), y=proportion.sign.lrt, group=r.effect))+
  #theme_classic()+
  ylim(0.3, 1)+
  geom_hline(yintercept=0.8, colour="red", lty=2)+
  facet_wrap(~r.slope.con)

```

### How many models converged, have a significant full-null model comparison, and a significant LRT of condition?  
```{r echo=FALSE}

lrt.data2 <- all.res2 %>%
  filter(full.null.p<0.05)%>%
  group_by(test.per, r.effect, r.slope.con) %>%
  summarise(lrt.p.con.mean2 = mean(lrt.p.con), 
            n.sign.lrt2 = length(lrt.p.con[lrt.p.con < 0.05]), 
            n.lrt = n.simus,#length(lrt.p.con), 
            proportion.sign.lrt2 = length(lrt.p.con[lrt.p.con < 0.05]) / n.simus)

lrt.data2
```

#### Plotting the proportion of significant LRTs for the predictor variable condition ONLY based on models that converged and with a significant full-null model comparison

```{r echo=FALSE}

p.exp4.con.power <- ggplot(data = lrt.data2, aes(y=proportion.sign.lrt2))+
        geom_boxplot(data = lrt.data2 %>% filter(r.slope.con == "0.45"), aes(x=as.factor(r.effect), y=proportion.sign.lrt2, group=as.factor(r.effect)), position = position_nudge(x = -.15), col = "darkorange", width=0.3)+
          geom_boxplot(data = lrt.data2 %>% filter(r.slope.con == "0.9"), aes(x=as.factor(r.effect), y=proportion.sign.lrt2, group=as.factor(r.effect)), position = position_nudge(x = .15), col = "dodgerblue", width=0.3)+
      ylim(0.0, 1)+
  geom_hline(yintercept = 0.8, colour = "black", lwd = 1.05, lty = 3) +
      facet_wrap(~test.per)+
      ylab("Power") +
      xlab("Size of random effect") +
      theme_bw()
 p.exp4.con.power

```

#### Plotting the intercepts
```{r echo=FALSE}
#some preparation for plotting:
par(mar=c(3, 3, 0.2, 0.2), mgp=c(1.7, 0.3, 0), tcl=-0.15, las=1)
where=as.numeric(as.factor(paste(all.res2$r.effect, all.res2$r.slope.con,
sep="_")))

plot(x=where, y=all.res2$icpt, xlab="", xaxt="n", pch=19,
col=grey(level=0.5, alpha=0.5), cex=1.5)
abline(h=coefs["(Intercept)"])
mtext(text=rep(x=r.slope.con, times=length(r.effects)), side=1, line=0.2,
at=1:(length(r.effects)*length(r.slope.con)), cex=1)
mtext(text="r.slope", side=1, line=0.2, at=0.5, cex=1)
mtext(text=rep(x=r.effects, each=length(r.slope.con)), side=1, line=1.4,
at=1:(length(r.effects)*length(r.slope.con)), cex=1)
mtext(text="re:", side=1, line=1.4, at=0.5, cex=1)
abline(v=(1:length(r.effects))[-length(r.effects)]*length(r.slope.con)+0.5,
lty=2)
```



```{r echo=FALSE}
ggplot(data = all.res2, aes(x=as.factor(r.effect), y=icpt))+
  geom_jitter( alpha=0.5, col="grey")+
  geom_boxplot(aes(x=as.factor(r.effect), y=icpt, group=r.effect), alpha=0.1, outlier.colour="white")+
  geom_hline(yintercept=coefs["(Intercept)"], colour="red", lty=2)+
  facet_wrap(~r.slope.con)
```



#### Plotting the fixed effect of condition
```{r echo=FALSE}

plot(x=where, y=all.res2$conditiontest, xlab="", xaxt="n", pch=19,
col=grey(level=0.5, alpha=0.5), cex=1.5)
abline(h=coefs["conditiontest"])
mtext(text=rep(x=r.slope.con, times=length(r.effects)), side=1, line=0.2,
at=1:(length(r.effects)*length(r.slope.con)), cex=1)
mtext(text="r.slope", side=1, line=0.2, at=0.5, cex=1)
mtext(text=rep(x=r.effects, each=length(r.slope.con)), side=1, line=1.4,
at=1:(length(r.effects)*length(r.slope.con)), cex=1)
mtext(text="re:", side=1, line=1.4, at=0.5, cex=1)
abline(v=(1:length(r.effects))[-length(r.effects)]*length(r.slope.con)+0.5,
lty=2)
```

```{r echo=FALSE}
p.exp4.con.est <- ggplot(data = all.res2, aes(x = as.factor(r.effect), y = conditiontest)) +
  geom_jitter(data = all.res2, aes(x = as.factor(r.effect), y = conditiontest, color = as.factor(r.slope.con)), size = 1.5, position = position_jitterdodge(dodge.width = 0.8, jitter.width = 0.5), alpha = .1) +
  scale_color_manual(values = c("darkorange", "dodgerblue"), name = "Random slopes") +
  geom_boxplot(data = all.res2 %>% filter(r.slope.con == "0.45"), aes(x = as.factor(r.effect), y = conditiontest, group = as.factor(r.effect)), position = position_nudge(x = -.2), width = 0.3, alpha = 0.1, outlier.colour = "white") +
  geom_boxplot(data = all.res2 %>% filter(r.slope.con == "0.9"), aes(x = as.factor(r.effect), y = conditiontest, group = as.factor(r.effect)), position = position_nudge(x = .2), width = 0.3, alpha = 0.1, outlier.colour = "white") +
  facet_wrap(~test.per) +
  geom_hline(yintercept = 0, colour = "black", alpha = 0.5) +
  geom_hline(data = data.frame(test.per = "0.65"), aes(yintercept = coefs["conditiontest"]), colour = "red", lwd = 1.05, lty = 2, alpha = 0.7) +
  geom_hline(data = data.frame(test.per = "0.55"), aes(yintercept = qlogis(0.55) - qlogis(1 / 4)), colour = "red", lwd = 1.05, lty = 2, alpha = 0.7) +
  ylim(-0.3, 3.2)+
  ylab("Condition fixed effect") +
  xlab("Size of random intercept") +
  theme_bw() +
  theme(legend.position = "none")

p.legend <- ggplot(data = all.res2 %>% mutate(r.slope.con = fct_recode(as.factor(r.slope.con), "medium" = "0.45", "large" = "0.9")), aes(x = as.factor(r.effect), y = conditiontest)) +
  geom_point(aes(colour = as.factor(r.slope.con))) +
  scale_color_manual(values = c("darkorange", "dodgerblue"), name = "Random slope") +
  theme_classic() +
  theme(legend.direction = "horizontal", legend.box.background = element_rect(colour = "black"))

p.leg <- get_legend(p.legend)

p.exp4.con <- plot_grid(p.exp4.con.power, p.exp4.con.est, labels = c("c", "d"), rel_widths = c(1, 1))
p.exp4.con2 <- ggdraw(plot_grid(p.con,p.exp4.con, p.leg, ncol = 1, nrow = 3, rel_heights = c(1,1, 0.15)))#p.con is created in power_analysis_binomial_GLMM_Exp3.Rmd
ggsave(p.exp4.con2, filename = "Exp3 and 4_condition_model.png", scale = 0.5, height = 14, width = 16)
```


#### Plotting the random intercept  
```{r echo=FALSE}
plot(x=where, y=all.res2$re.sd, xlab="", xaxt="n", pch=19,
col=grey(level=0.5, alpha=0.5), cex=1.5)
hll=1.0
where2=((1:length(r.effects))-1)*length(r.slope.con)+1.5
segments(x0=where2-hll, x1=where2+hll, y0=r.effects, y1=r.effects)
mtext(text=rep(x=r.slope.con, times=length(r.effects)), side=1, line=0.2,
at=1:(length(r.effects)*length(r.slope.con)), cex=1)
mtext(text="r.slope", side=1, line=0.2, at=0.5, cex=1)
mtext(text=rep(x=r.effects, each=length(r.slope.con)), side=1, line=1.4,
at=1:(length(r.effects)*length(r.slope.con)), cex=1)
mtext(text="re:", side=1, line=1.4, at=0.5, cex=1)
abline(v=(1:length(r.effects))[-length(r.effects)]*length(r.slope.con)+0.5,
lty=2)
```


```{r echo=FALSE}
ggplot(data = all.res2, aes(x=as.factor(r.effect), y=re.sd))+
  geom_jitter( alpha=0.5, col="grey")+
  geom_boxplot(aes(x=as.factor(r.effect), y=re.sd, group=r.effect), alpha=0.1, outlier.colour="white")+
  facet_wrap(~r.slope.con)
```


#### Plotting the full-null model comparison p-values
```{r echo=FALSE}
ggplot(data = all.res2, aes(y=full.null.p))+
  geom_jitter(aes(x=as.factor(r.effect), y=full.null.p), alpha=0.5, col="grey")+
  geom_boxplot(aes(x=as.factor(r.effect), y=full.null.p, group=r.effect), alpha=0.1, outlier.colour="white")+
  #theme_classic()+
  scale_y_continuous(trans='log10')+
  geom_hline(yintercept=0.05, colour="red", lty=2)+
  facet_wrap(~r.slope.con)

```

#### Plotting the LRT p-values of condition
```{r echo=FALSE}
ggplot(data = all.res2, aes(y=lrt.p.con))+
  geom_jitter(aes(x=as.factor(r.effect), y=lrt.p.con), alpha=0.5, col="grey")+
  geom_boxplot(aes(x=as.factor(r.effect), y=lrt.p.con, group=r.effect), alpha=0.1, outlier.colour="white")+
  #theme_classic()+
  scale_y_continuous(trans='log10')+
  geom_hline(yintercept=0.05, colour="red", lty=2)+
  facet_wrap(~r.slope.con)

```

